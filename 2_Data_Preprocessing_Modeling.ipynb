{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Data Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will focus on preprocessing data to bring them optimal size and format using data augmentation parameters. Once the preprocessing complete, I will train various Tensorflow Keras \"sequential\" and \"\"convolutional\" networks as well as pre-trained models to sample transfer learning to come up with best results. As the classes are imbalanced, my success metrics should be Precision and Recall. Specifically Recall score is the most important as our goal is to focus on minimizing false negative rates to not classify a patient as healthy while in fact they have pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, ZeroPadding2D, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './data/chest_xray/train/'\n",
    "test_dir = './data/chest_xray/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['normal', 'pneumonia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually checked the images and found that there are a lot of variations for such a small dataset. The hight/width ratio, zooming range, angle of the body etc features differ among differen Xray images. Even the physical dimensions of images are vastly different. This makes it harder to train a model that will give high accuracy rate. I decided to use generator class to generate more images within train data with optimal rotation_range, shear_range, zoom_range, horizontal_flip (mirroring randomly selected images) to get additional observations to train the model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation configuration to be used while training\n",
    "train_generator = ImageDataGenerator(\n",
    "                            rotation_range=20,\n",
    "                            width_shift_range=0.25,\n",
    "                            height_shift_range=0.25,\n",
    "                            rescale=1./255,\n",
    "                            shear_range=0.25,\n",
    "                            zoom_range=0.25,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will resize images to 224x224 px value and turn them to grayscale to only save the brightness and get rid of RGB values as the images are alrady provided as grayscale. It will help the train process run faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5232 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = DirectoryIterator(train_dir,\n",
    "                             train_generator,\n",
    "                             target_size = (224, 224),\n",
    "                             color_mode = 'rgb',\n",
    "                             batch_size = 16,\n",
    "                             classes=classes,\n",
    "                             class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation configuration to be used for validation\n",
    "test_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = DirectoryIterator(test_dir,\n",
    "                             test_generator,\n",
    "                             target_size = (224, 224),\n",
    "                             color_mode = 'rgb',\n",
    "                             batch_size = 16, # set batch size a number that divides sample size\n",
    "                             classes=classes,\n",
    "                             class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor size of train images\n",
    "train_set.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor size of test images\n",
    "test_set.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_set.filenames)\n",
    "test_size = len(test_set.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5232, 624)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sequential model\n",
    "model1 = Sequential()\n",
    "\n",
    "# Add flatten layer as input layer\n",
    "model1.add(Flatten(input_shape = train_set.image_shape))\n",
    "\n",
    "# Add a densely-connected layer with X neurons\n",
    "model1.add(Dense(units = 10000,\n",
    "                 activation='relu'))\n",
    "\n",
    "# Add regularization\n",
    "model1.add(Dropout(rate = 0.30))\n",
    "\n",
    "# Add a second densely-connected layer with X neurons\n",
    "model1.add(Dense(units = 128,\n",
    "                activation='relu'))\n",
    "\n",
    "# Add a third densely-connected layer with X neurons\n",
    "model1.add(Dense(units = 64,\n",
    "                 activation='relu'))\n",
    "\n",
    "# Add regularization\n",
    "model1.add(Dropout(rate = 0.10))\n",
    "\n",
    "# Add a fourth densely-connected layer with X neurons\n",
    "model1.add(Dense(units = 32,\n",
    "                 activation='relu'))\n",
    "\n",
    "# Add output layer\n",
    "model1.add(Dense(units = 2,\n",
    "    activation='sigmoid'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = SGD(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the first model\n",
    "model1.compile(optimizer = opt,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping_monitor = EarlyStopping(patience = 5, \n",
    "                                       monitor = \"val_accuracy\", \n",
    "                                       mode=\"max\", \n",
    "                                       verbose = 2)\n",
    "\n",
    "# Define batch size (a divisor of test sample size)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on training data\n",
    "history = model1.fit_generator(generator = train_set,\n",
    "                              validation_data = test_set,\n",
    "                              epochs = 25,\n",
    "#                               callbacks=[early_stopping_monitor],\n",
    "                              steps_per_epoch = train_size/batch_size, \n",
    "                              validation_steps = test_size/batch_size,\n",
    "                              shuffle=False,\n",
    "                              verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.predict_generator(generator = test_set, \n",
    "                                       verbose = 2,\n",
    "                                       steps = test_size/batch_size\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.argmax(predictions, axis = 1) \n",
    "y_true = test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_true) == len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_true, y_hat)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM,  figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sequential model\n",
    "model2 = Sequential()\n",
    "\n",
    "# Add convolution and pooling as input layer\n",
    "model2.add(Conv2D(filters = 32, # number of filters\n",
    "                 kernel_size = (3, 3), # height/width of filter\n",
    "                 input_shape = train_set.image_shape, # shape of input (image)\n",
    "                 activation = 'relu')) # activation function\n",
    "\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2))) # dimensions of region of pooling\n",
    "\n",
    "# Add a second convolutional layer\n",
    "model2.add(Conv2D(filters = 32, \n",
    "                 kernel_size = (3, 3),\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add a flattening layer\n",
    "model2.add(Flatten())\n",
    "\n",
    "# Add a densely-connected layer\n",
    "model2.add(Dense(units = 128,\n",
    "                activation = 'relu'))\n",
    "\n",
    "# Add output layer\n",
    "model2.add(Dense(units = 2,\n",
    "                activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = 'adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on training data\n",
    "history = model2.fit_generator(generator = train_set,\n",
    "                              validation_data = test_set,\n",
    "                              epochs = 10,\n",
    "                              callbacks=[early_stopping_monitor],\n",
    "                              steps_per_epoch = train_size/batch_size, \n",
    "                              validation_steps = test_size/batch_size,\n",
    "                              shuffle = True,\n",
    "                              verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 - Pre-trained Model (VGG16 Convolutional Base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use the artichecture of a pre-trained model as I was curious about transfer learning outcome. Transfer learning is using a pre-trained model and its weights on a different dataset. I chose to create an instance from VGG16 convolutional neural network model which is popular from ImageNet competition. This would allow me to save a lot of time while testing the performance of my data with an additional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = VGG16(weights = 'imagenet', \n",
    "#                  include_top = False,\n",
    "#                  input_shape = train_set.image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=train_set.image_shape, filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='accuracy', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=False, mode='max', save_freq=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.31250, saving model to vgg16_1.h5\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (21.719507). Check your callbacks.\n",
      "  1/100 [..............................] - ETA: 1:10:19 - loss: 0.6933 - accuracy: 0.3125\n",
      "Epoch 00001: accuracy improved from 0.31250 to 0.43750, saving model to vgg16_1.h5\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (18.673439). Check your callbacks.\n",
      "  2/100 [..............................] - ETA: 1:02:53 - loss: 0.6994 - accuracy: 0.4375\n",
      "Epoch 00001: accuracy improved from 0.43750 to 0.54167, saving model to vgg16_1.h5\n",
      "  3/100 [..............................] - ETA: 59:29 - loss: 0.6969 - accuracy: 0.5417  \n",
      "Epoch 00001: accuracy improved from 0.54167 to 0.54688, saving model to vgg16_1.h5\n",
      "  4/100 [>.............................] - ETA: 55:52 - loss: 0.6954 - accuracy: 0.5469\n",
      "Epoch 00001: accuracy improved from 0.54688 to 0.58750, saving model to vgg16_1.h5\n",
      "  5/100 [>.............................] - ETA: 54:22 - loss: 0.6865 - accuracy: 0.5875\n",
      "Epoch 00001: accuracy improved from 0.58750 to 0.59375, saving model to vgg16_1.h5\n",
      "  6/100 [>.............................] - ETA: 52:00 - loss: 0.9796 - accuracy: 0.5938\n",
      "Epoch 00001: accuracy improved from 0.59375 to 0.61607, saving model to vgg16_1.h5\n",
      "  7/100 [=>............................] - ETA: 50:42 - loss: 0.9315 - accuracy: 0.6161\n",
      "Epoch 00001: accuracy did not improve from 0.61607\n",
      "  8/100 [=>............................] - ETA: 47:32 - loss: 0.9019 - accuracy: 0.6016\n",
      "Epoch 00001: accuracy improved from 0.61607 to 0.63194, saving model to vgg16_1.h5\n",
      "  9/100 [=>............................] - ETA: 45:53 - loss: 0.8759 - accuracy: 0.6319\n",
      "Epoch 00001: accuracy did not improve from 0.63194\n",
      " 10/100 [==>...........................] - ETA: 43:40 - loss: 0.8568 - accuracy: 0.6313\n",
      "Epoch 00001: accuracy improved from 0.63194 to 0.64205, saving model to vgg16_1.h5\n",
      " 11/100 [==>...........................] - ETA: 42:31 - loss: 0.8402 - accuracy: 0.6420\n",
      "Epoch 00001: accuracy improved from 0.64205 to 0.65625, saving model to vgg16_1.h5\n",
      " 12/100 [==>...........................] - ETA: 41:30 - loss: 0.8255 - accuracy: 0.6562\n",
      "Epoch 00001: accuracy improved from 0.65625 to 0.66827, saving model to vgg16_1.h5\n",
      " 13/100 [==>...........................] - ETA: 40:35 - loss: 0.8125 - accuracy: 0.6683\n",
      "Epoch 00001: accuracy improved from 0.66827 to 0.68750, saving model to vgg16_1.h5\n",
      " 14/100 [===>..........................] - ETA: 39:55 - loss: 0.7992 - accuracy: 0.6875\n",
      "Epoch 00001: accuracy improved from 0.68750 to 0.69583, saving model to vgg16_1.h5\n",
      " 15/100 [===>..........................] - ETA: 39:09 - loss: 0.7879 - accuracy: 0.6958\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 16/100 [===>..........................] - ETA: 37:55 - loss: 0.7816 - accuracy: 0.6875\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 17/100 [====>.........................] - ETA: 36:49 - loss: 0.7732 - accuracy: 0.6875\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 18/100 [====>.........................] - ETA: 35:47 - loss: 0.7653 - accuracy: 0.6875\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 19/100 [====>.........................] - ETA: 34:49 - loss: 0.7599 - accuracy: 0.6842\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 20/100 [=====>........................] - ETA: 33:56 - loss: 0.7571 - accuracy: 0.6781\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 21/100 [=====>........................] - ETA: 33:05 - loss: 0.7490 - accuracy: 0.6815\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 22/100 [=====>........................] - ETA: 32:18 - loss: 0.7414 - accuracy: 0.6847\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 23/100 [=====>........................] - ETA: 31:33 - loss: 0.7384 - accuracy: 0.6821\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 24/100 [======>.......................] - ETA: 30:49 - loss: 0.7291 - accuracy: 0.6875\n",
      "Epoch 00001: accuracy did not improve from 0.69583\n",
      " 25/100 [======>.......................] - ETA: 30:08 - loss: 0.7197 - accuracy: 0.6925\n",
      "Epoch 00001: accuracy improved from 0.69583 to 0.69712, saving model to vgg16_1.h5\n",
      " 26/100 [======>.......................] - ETA: 29:48 - loss: 0.7106 - accuracy: 0.6971\n",
      "Epoch 00001: accuracy improved from 0.69712 to 0.70139, saving model to vgg16_1.h5\n",
      " 27/100 [=======>......................] - ETA: 29:29 - loss: 0.7029 - accuracy: 0.7014\n",
      "Epoch 00001: accuracy did not improve from 0.70139\n",
      " 28/100 [=======>......................] - ETA: 28:51 - loss: 0.7162 - accuracy: 0.6942\n",
      "Epoch 00001: accuracy did not improve from 0.70139\n",
      " 29/100 [=======>......................] - ETA: 28:13 - loss: 0.7083 - accuracy: 0.6983\n",
      "Epoch 00001: accuracy improved from 0.70139 to 0.70625, saving model to vgg16_1.h5\n",
      " 30/100 [========>.....................] - ETA: 27:51 - loss: 0.6975 - accuracy: 0.7063\n",
      "Epoch 00001: accuracy did not improve from 0.70625\n",
      " 31/100 [========>.....................] - ETA: 27:16 - loss: 0.6951 - accuracy: 0.7056\n",
      "Epoch 00001: accuracy improved from 0.70625 to 0.70703, saving model to vgg16_1.h5\n",
      " 32/100 [========>.....................] - ETA: 26:56 - loss: 0.6913 - accuracy: 0.7070\n",
      "Epoch 00001: accuracy did not improve from 0.70703\n",
      " 33/100 [========>.....................] - ETA: 26:22 - loss: 0.6905 - accuracy: 0.7045\n",
      "Epoch 00001: accuracy did not improve from 0.70703\n",
      " 34/100 [=========>....................] - ETA: 25:50 - loss: 0.6885 - accuracy: 0.7040\n",
      "Epoch 00001: accuracy improved from 0.70703 to 0.70714, saving model to vgg16_1.h5\n",
      " 35/100 [=========>....................] - ETA: 25:32 - loss: 0.6844 - accuracy: 0.7071\n",
      "Epoch 00001: accuracy did not improve from 0.70714\n",
      " 36/100 [=========>....................] - ETA: 24:59 - loss: 0.6827 - accuracy: 0.7066\n",
      "Epoch 00001: accuracy did not improve from 0.70714\n",
      " 37/100 [==========>...................] - ETA: 24:28 - loss: 0.6811 - accuracy: 0.7061\n",
      "Epoch 00001: accuracy improved from 0.70714 to 0.70724, saving model to vgg16_1.h5\n",
      " 38/100 [==========>...................] - ETA: 24:07 - loss: 0.6786 - accuracy: 0.7072\n",
      "Epoch 00001: accuracy improved from 0.70724 to 0.70994, saving model to vgg16_1.h5\n",
      " 39/100 [==========>...................] - ETA: 23:45 - loss: 0.6751 - accuracy: 0.7099\n",
      "Epoch 00001: accuracy did not improve from 0.70994\n",
      " 40/100 [===========>..................] - ETA: 23:14 - loss: 0.6738 - accuracy: 0.7094\n",
      "Epoch 00001: accuracy improved from 0.70994 to 0.71341, saving model to vgg16_1.h5\n",
      " 41/100 [===========>..................] - ETA: 22:53 - loss: 0.6696 - accuracy: 0.7134\n",
      "Epoch 00001: accuracy improved from 0.71341 to 0.71726, saving model to vgg16_1.h5\n",
      " 42/100 [===========>..................] - ETA: 22:36 - loss: 0.6654 - accuracy: 0.7173\n",
      "Epoch 00001: accuracy improved from 0.71726 to 0.72384, saving model to vgg16_1.h5\n",
      " 43/100 [===========>..................] - ETA: 22:13 - loss: 0.6592 - accuracy: 0.7238\n",
      "Epoch 00001: accuracy improved from 0.72384 to 0.72585, saving model to vgg16_1.h5\n",
      " 44/100 [============>.................] - ETA: 21:51 - loss: 0.6562 - accuracy: 0.7259\n",
      "Epoch 00001: accuracy improved from 0.72585 to 0.72917, saving model to vgg16_1.h5\n",
      " 45/100 [============>.................] - ETA: 21:29 - loss: 0.6519 - accuracy: 0.7292\n",
      "Epoch 00001: accuracy improved from 0.72917 to 0.73234, saving model to vgg16_1.h5\n",
      " 46/100 [============>.................] - ETA: 21:09 - loss: 0.6474 - accuracy: 0.7323\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 47/100 [=============>................] - ETA: 20:40 - loss: 0.6488 - accuracy: 0.7301\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 48/100 [=============>................] - ETA: 20:12 - loss: 0.6485 - accuracy: 0.7292\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 49/100 [=============>................] - ETA: 19:44 - loss: 0.6497 - accuracy: 0.7270\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 50/100 [==============>...............] - ETA: 19:17 - loss: 0.6502 - accuracy: 0.7250\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 51/100 [==============>...............] - ETA: 18:49 - loss: 0.6479 - accuracy: 0.7279\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52/100 [==============>...............] - ETA: 18:23 - loss: 0.6504 - accuracy: 0.7236\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 53/100 [==============>...............] - ETA: 17:56 - loss: 0.6516 - accuracy: 0.7205\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 54/100 [===============>..............] - ETA: 17:29 - loss: 0.6514 - accuracy: 0.7199\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 55/100 [===============>..............] - ETA: 17:03 - loss: 0.6508 - accuracy: 0.7193\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 56/100 [===============>..............] - ETA: 16:37 - loss: 0.6496 - accuracy: 0.7199\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 57/100 [================>.............] - ETA: 16:12 - loss: 0.6506 - accuracy: 0.7171\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 58/100 [================>.............] - ETA: 15:46 - loss: 0.6516 - accuracy: 0.7144\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 59/100 [================>.............] - ETA: 15:21 - loss: 0.6478 - accuracy: 0.7193\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 60/100 [=================>............] - ETA: 14:57 - loss: 0.6467 - accuracy: 0.7198\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 61/100 [=================>............] - ETA: 14:32 - loss: 0.6434 - accuracy: 0.7234\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 62/100 [=================>............] - ETA: 14:07 - loss: 0.6430 - accuracy: 0.7228\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 63/100 [=================>............] - ETA: 13:43 - loss: 0.6444 - accuracy: 0.7202\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 64/100 [==================>...........] - ETA: 13:19 - loss: 0.6467 - accuracy: 0.7168\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 65/100 [==================>...........] - ETA: 12:55 - loss: 0.6448 - accuracy: 0.7183\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 66/100 [==================>...........] - ETA: 12:31 - loss: 0.6444 - accuracy: 0.7178\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 67/100 [===================>..........] - ETA: 12:07 - loss: 0.6434 - accuracy: 0.7183\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 68/100 [===================>..........] - ETA: 11:44 - loss: 0.6445 - accuracy: 0.7160\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 69/100 [===================>..........] - ETA: 11:20 - loss: 0.6428 - accuracy: 0.7174\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 70/100 [====================>.........] - ETA: 10:57 - loss: 0.6453 - accuracy: 0.7134\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 71/100 [====================>.........] - ETA: 10:33 - loss: 0.6438 - accuracy: 0.7148\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 72/100 [====================>.........] - ETA: 10:10 - loss: 0.6429 - accuracy: 0.7153\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 73/100 [====================>.........] - ETA: 9:48 - loss: 0.6438 - accuracy: 0.7132 \n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 74/100 [=====================>........] - ETA: 9:25 - loss: 0.6435 - accuracy: 0.7128\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 75/100 [=====================>........] - ETA: 9:02 - loss: 0.6432 - accuracy: 0.7125\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 76/100 [=====================>........] - ETA: 8:39 - loss: 0.6435 - accuracy: 0.7113\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 77/100 [======================>.......] - ETA: 8:17 - loss: 0.6438 - accuracy: 0.7102\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 78/100 [======================>.......] - ETA: 7:54 - loss: 0.6420 - accuracy: 0.7123\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 79/100 [======================>.......] - ETA: 7:32 - loss: 0.6400 - accuracy: 0.7144\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 80/100 [=======================>......] - ETA: 7:10 - loss: 0.6384 - accuracy: 0.7156\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 81/100 [=======================>......] - ETA: 6:48 - loss: 0.6375 - accuracy: 0.7160\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 82/100 [=======================>......] - ETA: 6:26 - loss: 0.6382 - accuracy: 0.7149\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 83/100 [=======================>......] - ETA: 6:04 - loss: 0.6365 - accuracy: 0.7161\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 84/100 [========================>.....] - ETA: 5:42 - loss: 0.6356 - accuracy: 0.7165\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 85/100 [========================>.....] - ETA: 5:20 - loss: 0.6348 - accuracy: 0.7169\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 86/100 [========================>.....] - ETA: 4:58 - loss: 0.6323 - accuracy: 0.7188\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 87/100 [=========================>....] - ETA: 4:37 - loss: 0.6315 - accuracy: 0.7191\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 88/100 [=========================>....] - ETA: 4:15 - loss: 0.6289 - accuracy: 0.7209\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 89/100 [=========================>....] - ETA: 3:53 - loss: 0.6273 - accuracy: 0.7219\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 90/100 [==========================>...] - ETA: 3:32 - loss: 0.6280 - accuracy: 0.7215\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 91/100 [==========================>...] - ETA: 3:10 - loss: 0.6275 - accuracy: 0.7218\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 92/100 [==========================>...] - ETA: 2:49 - loss: 0.6288 - accuracy: 0.7208\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 93/100 [==========================>...] - ETA: 2:28 - loss: 0.6265 - accuracy: 0.7224\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 94/100 [===========================>..] - ETA: 2:06 - loss: 0.6281 - accuracy: 0.7207\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 95/100 [===========================>..] - ETA: 1:45 - loss: 0.6281 - accuracy: 0.7204\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 96/100 [===========================>..] - ETA: 1:24 - loss: 0.6262 - accuracy: 0.7220\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 97/100 [============================>.] - ETA: 1:03 - loss: 0.6256 - accuracy: 0.7223\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 98/100 [============================>.] - ETA: 42s - loss: 0.6250 - accuracy: 0.7226 \n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      " 99/100 [============================>.] - ETA: 21s - loss: 0.6260 - accuracy: 0.7210\n",
      "Epoch 00001: accuracy did not improve from 0.73234\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "100/100 [==============================] - 2151s 22s/step - loss: 0.6260 - accuracy: 0.7206 - val_loss: 0.6959 - val_accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.73234 to 0.87500, saving model to vgg16_1.h5\n",
      "  1/100 [..............................] - ETA: 42:59 - loss: 0.4714 - accuracy: 0.8750\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "  2/100 [..............................] - ETA: 36:34 - loss: 0.5711 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "  3/100 [..............................] - ETA: 34:19 - loss: 0.5549 - accuracy: 0.7708\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "  4/100 [>.............................] - ETA: 33:02 - loss: 0.5467 - accuracy: 0.7812\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "  5/100 [>.............................] - ETA: 32:10 - loss: 0.5413 - accuracy: 0.7875\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "  6/100 [>.............................] - ETA: 31:25 - loss: 0.5547 - accuracy: 0.7708\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "  7/100 [=>............................] - ETA: 30:50 - loss: 0.5642 - accuracy: 0.7589\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "  8/100 [=>............................] - ETA: 30:18 - loss: 0.5646 - accuracy: 0.7578\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/100 [=>............................] - ETA: 29:49 - loss: 0.5523 - accuracy: 0.7708\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 10/100 [==>...........................] - ETA: 29:22 - loss: 0.5536 - accuracy: 0.7688\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 11/100 [==>...........................] - ETA: 28:56 - loss: 0.5545 - accuracy: 0.7670\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 12/100 [==>...........................] - ETA: 28:32 - loss: 0.5445 - accuracy: 0.7760\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 13/100 [==>...........................] - ETA: 28:08 - loss: 0.5352 - accuracy: 0.7837\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 14/100 [===>..........................] - ETA: 27:46 - loss: 0.5536 - accuracy: 0.7679\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 15/100 [===>..........................] - ETA: 27:22 - loss: 0.5699 - accuracy: 0.7542\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 16/100 [===>..........................] - ETA: 27:00 - loss: 0.5788 - accuracy: 0.7461\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 17/100 [====>.........................] - ETA: 26:39 - loss: 0.5737 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 18/100 [====>.........................] - ETA: 26:17 - loss: 0.5806 - accuracy: 0.7431\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 19/100 [====>.........................] - ETA: 25:57 - loss: 0.5796 - accuracy: 0.7434\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 20/100 [=====>........................] - ETA: 25:36 - loss: 0.5727 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 21/100 [=====>........................] - ETA: 25:16 - loss: 0.5693 - accuracy: 0.7530\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 22/100 [=====>........................] - ETA: 24:56 - loss: 0.5609 - accuracy: 0.7614\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 23/100 [=====>........................] - ETA: 24:33 - loss: 0.5583 - accuracy: 0.7636\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 24/100 [======>.......................] - ETA: 24:10 - loss: 0.5716 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 25/100 [======>.......................] - ETA: 23:46 - loss: 0.5787 - accuracy: 0.7425\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 26/100 [======>.......................] - ETA: 23:26 - loss: 0.5781 - accuracy: 0.7428\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 27/100 [=======>......................] - ETA: 23:06 - loss: 0.5754 - accuracy: 0.7454\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 28/100 [=======>......................] - ETA: 22:47 - loss: 0.5750 - accuracy: 0.7455\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 29/100 [=======>......................] - ETA: 22:28 - loss: 0.5746 - accuracy: 0.7457\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 30/100 [========>.....................] - ETA: 22:10 - loss: 0.5724 - accuracy: 0.7479\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 31/100 [========>.....................] - ETA: 21:51 - loss: 0.5721 - accuracy: 0.7480\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 32/100 [========>.....................] - ETA: 21:32 - loss: 0.5811 - accuracy: 0.7383\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 33/100 [========>.....................] - ETA: 21:13 - loss: 0.5824 - accuracy: 0.7367\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 34/100 [=========>....................] - ETA: 20:53 - loss: 0.5853 - accuracy: 0.7335\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 35/100 [=========>....................] - ETA: 20:34 - loss: 0.5864 - accuracy: 0.7321\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 36/100 [=========>....................] - ETA: 20:15 - loss: 0.5843 - accuracy: 0.7344\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 37/100 [==========>...................] - ETA: 19:56 - loss: 0.5838 - accuracy: 0.7348\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 38/100 [==========>...................] - ETA: 19:37 - loss: 0.5805 - accuracy: 0.7385\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 39/100 [==========>...................] - ETA: 19:18 - loss: 0.5774 - accuracy: 0.7420\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 40/100 [===========>..................] - ETA: 19:00 - loss: 0.5757 - accuracy: 0.7437\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 41/100 [===========>..................] - ETA: 18:40 - loss: 0.5741 - accuracy: 0.7454\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 42/100 [===========>..................] - ETA: 18:21 - loss: 0.5711 - accuracy: 0.7485\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 43/100 [===========>..................] - ETA: 18:02 - loss: 0.5737 - accuracy: 0.7456\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 44/100 [============>.................] - ETA: 17:43 - loss: 0.5721 - accuracy: 0.7472\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 45/100 [============>.................] - ETA: 17:24 - loss: 0.5705 - accuracy: 0.7486\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 46/100 [============>.................] - ETA: 17:05 - loss: 0.5704 - accuracy: 0.7486\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 47/100 [=============>................] - ETA: 16:46 - loss: 0.5716 - accuracy: 0.7473\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 48/100 [=============>................] - ETA: 16:27 - loss: 0.5743 - accuracy: 0.7448\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 49/100 [=============>................] - ETA: 16:08 - loss: 0.5740 - accuracy: 0.7449\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 50/100 [==============>...............] - ETA: 15:49 - loss: 0.5752 - accuracy: 0.7437\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 51/100 [==============>...............] - ETA: 15:30 - loss: 0.5736 - accuracy: 0.7451\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 52/100 [==============>...............] - ETA: 15:11 - loss: 0.5720 - accuracy: 0.7464\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 53/100 [==============>...............] - ETA: 14:52 - loss: 0.5745 - accuracy: 0.7441\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 54/100 [===============>..............] - ETA: 14:33 - loss: 0.5704 - accuracy: 0.7477\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 55/100 [===============>..............] - ETA: 14:14 - loss: 0.5676 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 56/100 [===============>..............] - ETA: 13:55 - loss: 0.5676 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 57/100 [================>.............] - ETA: 13:36 - loss: 0.5635 - accuracy: 0.7533\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 58/100 [================>.............] - ETA: 13:17 - loss: 0.5622 - accuracy: 0.7543\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 59/100 [================>.............] - ETA: 12:58 - loss: 0.5637 - accuracy: 0.7532\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 60/100 [=================>............] - ETA: 12:39 - loss: 0.5666 - accuracy: 0.7510\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 61/100 [=================>............] - ETA: 12:20 - loss: 0.5625 - accuracy: 0.7541\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 62/100 [=================>............] - ETA: 12:01 - loss: 0.5584 - accuracy: 0.7571\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 63/100 [=================>............] - ETA: 11:42 - loss: 0.5558 - accuracy: 0.7589\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 64/100 [==================>...........] - ETA: 11:23 - loss: 0.5547 - accuracy: 0.7598\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 65/100 [==================>...........] - ETA: 11:04 - loss: 0.5504 - accuracy: 0.7625\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 66/100 [==================>...........] - ETA: 10:45 - loss: 0.5529 - accuracy: 0.7614\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 67/100 [===================>..........] - ETA: 10:26 - loss: 0.5536 - accuracy: 0.7612\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68/100 [===================>..........] - ETA: 10:07 - loss: 0.5590 - accuracy: 0.7583\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 69/100 [===================>..........] - ETA: 9:48 - loss: 0.5593 - accuracy: 0.7582 \n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 70/100 [====================>.........] - ETA: 9:29 - loss: 0.5594 - accuracy: 0.7580\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 71/100 [====================>.........] - ETA: 9:10 - loss: 0.5595 - accuracy: 0.7579\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 72/100 [====================>.........] - ETA: 8:51 - loss: 0.5605 - accuracy: 0.7569\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 73/100 [====================>.........] - ETA: 8:32 - loss: 0.5587 - accuracy: 0.7586\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 74/100 [=====================>........] - ETA: 8:13 - loss: 0.5579 - accuracy: 0.7593\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 75/100 [=====================>........] - ETA: 7:54 - loss: 0.5580 - accuracy: 0.7592\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 76/100 [=====================>........] - ETA: 7:35 - loss: 0.5565 - accuracy: 0.7607\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 77/100 [======================>.......] - ETA: 7:16 - loss: 0.5589 - accuracy: 0.7581\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 78/100 [======================>.......] - ETA: 6:57 - loss: 0.5597 - accuracy: 0.7572\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 79/100 [======================>.......] - ETA: 6:38 - loss: 0.5613 - accuracy: 0.7555\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 80/100 [=======================>......] - ETA: 6:19 - loss: 0.5627 - accuracy: 0.7539\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 81/100 [=======================>......] - ETA: 6:00 - loss: 0.5628 - accuracy: 0.7539\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 82/100 [=======================>......] - ETA: 5:41 - loss: 0.5622 - accuracy: 0.7546\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 83/100 [=======================>......] - ETA: 5:22 - loss: 0.5623 - accuracy: 0.7545\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 84/100 [========================>.....] - ETA: 5:03 - loss: 0.5642 - accuracy: 0.7522\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 85/100 [========================>.....] - ETA: 4:44 - loss: 0.5643 - accuracy: 0.7522\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 86/100 [========================>.....] - ETA: 4:25 - loss: 0.5655 - accuracy: 0.7507\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 87/100 [=========================>....] - ETA: 4:06 - loss: 0.5638 - accuracy: 0.7529\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 88/100 [=========================>....] - ETA: 3:47 - loss: 0.5662 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 89/100 [=========================>....] - ETA: 3:28 - loss: 0.5663 - accuracy: 0.7500\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 90/100 [==========================>...] - ETA: 3:09 - loss: 0.5647 - accuracy: 0.7521\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 91/100 [==========================>...] - ETA: 2:50 - loss: 0.5647 - accuracy: 0.7521\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 92/100 [==========================>...] - ETA: 2:31 - loss: 0.5631 - accuracy: 0.7541\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 93/100 [==========================>...] - ETA: 2:12 - loss: 0.5621 - accuracy: 0.7554\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 94/100 [===========================>..] - ETA: 1:53 - loss: 0.5627 - accuracy: 0.7547\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 95/100 [===========================>..] - ETA: 1:34 - loss: 0.5616 - accuracy: 0.7559\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 96/100 [===========================>..] - ETA: 1:15 - loss: 0.5616 - accuracy: 0.7559\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 97/100 [============================>.] - ETA: 56s - loss: 0.5599 - accuracy: 0.7577 \n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 98/100 [============================>.] - ETA: 37s - loss: 0.5599 - accuracy: 0.7577\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      " 99/100 [============================>.] - ETA: 18s - loss: 0.5587 - accuracy: 0.7588\n",
      "Epoch 00002: accuracy did not improve from 0.87500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "100/100 [==============================] - 1951s 20s/step - loss: 0.5581 - accuracy: 0.7594 - val_loss: 0.7369 - val_accuracy: 0.5938\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  1/100 [..............................] - ETA: 31:03 - loss: 0.4925 - accuracy: 0.8125\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  2/100 [..............................] - ETA: 30:49 - loss: 0.4905 - accuracy: 0.8125\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  3/100 [..............................] - ETA: 30:34 - loss: 0.5424 - accuracy: 0.7708\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  4/100 [>.............................] - ETA: 30:09 - loss: 0.6326 - accuracy: 0.7031\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  5/100 [>.............................] - ETA: 29:56 - loss: 0.6194 - accuracy: 0.7125\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  6/100 [>.............................] - ETA: 29:35 - loss: 0.6235 - accuracy: 0.7083\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  7/100 [=>............................] - ETA: 29:20 - loss: 0.6150 - accuracy: 0.7143\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  8/100 [=>............................] - ETA: 29:00 - loss: 0.5993 - accuracy: 0.7266\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "  9/100 [=>............................] - ETA: 28:41 - loss: 0.5872 - accuracy: 0.7361\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 10/100 [==>...........................] - ETA: 28:22 - loss: 0.5918 - accuracy: 0.7312\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 11/100 [==>...........................] - ETA: 28:02 - loss: 0.5765 - accuracy: 0.7443\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 12/100 [==>...........................] - ETA: 27:44 - loss: 0.5637 - accuracy: 0.7552\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 13/100 [==>...........................] - ETA: 27:25 - loss: 0.5690 - accuracy: 0.7500\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 14/100 [===>..........................] - ETA: 27:07 - loss: 0.5685 - accuracy: 0.7500\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 15/100 [===>..........................] - ETA: 26:47 - loss: 0.5867 - accuracy: 0.7333\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 16/100 [===>..........................] - ETA: 26:28 - loss: 0.5895 - accuracy: 0.7305\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 17/100 [====>.........................] - ETA: 26:10 - loss: 0.5800 - accuracy: 0.7390\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 18/100 [====>.........................] - ETA: 25:51 - loss: 0.5754 - accuracy: 0.7431\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 19/100 [====>.........................] - ETA: 25:32 - loss: 0.5816 - accuracy: 0.7368\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 20/100 [=====>........................] - ETA: 25:12 - loss: 0.5742 - accuracy: 0.7437\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 21/100 [=====>........................] - ETA: 24:54 - loss: 0.5705 - accuracy: 0.7470\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 22/100 [=====>........................] - ETA: 24:35 - loss: 0.5731 - accuracy: 0.7443\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 23/100 [=====>........................] - ETA: 24:16 - loss: 0.5840 - accuracy: 0.7337\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 24/100 [======>.......................] - ETA: 23:57 - loss: 0.5858 - accuracy: 0.7318\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 25/100 [======>.......................] - ETA: 23:38 - loss: 0.5849 - accuracy: 0.7325\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/100 [======>.......................] - ETA: 23:19 - loss: 0.5841 - accuracy: 0.7332\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 27/100 [=======>......................] - ETA: 23:00 - loss: 0.5833 - accuracy: 0.7338\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 28/100 [=======>......................] - ETA: 22:41 - loss: 0.5804 - accuracy: 0.7366\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 29/100 [=======>......................] - ETA: 22:23 - loss: 0.5903 - accuracy: 0.7263\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 30/100 [========>.....................] - ETA: 22:04 - loss: 0.5895 - accuracy: 0.7271\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 31/100 [========>.....................] - ETA: 21:45 - loss: 0.5906 - accuracy: 0.7258\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 32/100 [========>.....................] - ETA: 21:26 - loss: 0.5898 - accuracy: 0.7266\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 33/100 [========>.....................] - ETA: 21:08 - loss: 0.5890 - accuracy: 0.7273\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 34/100 [=========>....................] - ETA: 20:49 - loss: 0.5850 - accuracy: 0.7316\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 35/100 [=========>....................] - ETA: 20:30 - loss: 0.5844 - accuracy: 0.7321\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 36/100 [=========>....................] - ETA: 20:11 - loss: 0.5839 - accuracy: 0.7326\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 37/100 [==========>...................] - ETA: 19:52 - loss: 0.5818 - accuracy: 0.7348\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 38/100 [==========>...................] - ETA: 19:33 - loss: 0.5799 - accuracy: 0.7368\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 39/100 [==========>...................] - ETA: 19:14 - loss: 0.5840 - accuracy: 0.7324\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 40/100 [===========>..................] - ETA: 18:55 - loss: 0.5864 - accuracy: 0.7297\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 41/100 [===========>..................] - ETA: 18:36 - loss: 0.5873 - accuracy: 0.7287\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 42/100 [===========>..................] - ETA: 18:17 - loss: 0.5910 - accuracy: 0.7247\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 43/100 [===========>..................] - ETA: 17:58 - loss: 0.5890 - accuracy: 0.7267\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 44/100 [============>.................] - ETA: 17:39 - loss: 0.5846 - accuracy: 0.7315\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 45/100 [============>.................] - ETA: 17:20 - loss: 0.5816 - accuracy: 0.7347\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 46/100 [============>.................] - ETA: 17:01 - loss: 0.5812 - accuracy: 0.7351\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 47/100 [=============>................] - ETA: 16:42 - loss: 0.5821 - accuracy: 0.7340\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 48/100 [=============>................] - ETA: 16:24 - loss: 0.5793 - accuracy: 0.7370\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 49/100 [=============>................] - ETA: 16:04 - loss: 0.5777 - accuracy: 0.7385\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 50/100 [==============>...............] - ETA: 15:46 - loss: 0.5775 - accuracy: 0.7387\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 51/100 [==============>...............] - ETA: 15:27 - loss: 0.5772 - accuracy: 0.7390\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 52/100 [==============>...............] - ETA: 15:08 - loss: 0.5769 - accuracy: 0.7392\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 53/100 [==============>...............] - ETA: 14:49 - loss: 0.5742 - accuracy: 0.7417\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 54/100 [===============>..............] - ETA: 14:30 - loss: 0.5728 - accuracy: 0.7431\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 55/100 [===============>..............] - ETA: 14:11 - loss: 0.5726 - accuracy: 0.7432\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 56/100 [===============>..............] - ETA: 13:52 - loss: 0.5712 - accuracy: 0.7444\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 57/100 [================>.............] - ETA: 13:33 - loss: 0.5723 - accuracy: 0.7434\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 58/100 [================>.............] - ETA: 13:14 - loss: 0.5733 - accuracy: 0.7425\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 59/100 [================>.............] - ETA: 12:56 - loss: 0.5732 - accuracy: 0.7426\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 60/100 [=================>............] - ETA: 12:37 - loss: 0.5705 - accuracy: 0.7448\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 61/100 [=================>............] - ETA: 12:18 - loss: 0.5753 - accuracy: 0.7408\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 62/100 [=================>............] - ETA: 11:59 - loss: 0.5715 - accuracy: 0.7440\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 63/100 [=================>............] - ETA: 11:40 - loss: 0.5690 - accuracy: 0.7460\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 64/100 [==================>...........] - ETA: 11:21 - loss: 0.5677 - accuracy: 0.7471\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 65/100 [==================>...........] - ETA: 11:02 - loss: 0.5665 - accuracy: 0.7481\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 66/100 [==================>...........] - ETA: 10:43 - loss: 0.5701 - accuracy: 0.7453\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 67/100 [===================>..........] - ETA: 10:24 - loss: 0.5712 - accuracy: 0.7444\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 68/100 [===================>..........] - ETA: 10:05 - loss: 0.5699 - accuracy: 0.7454\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 69/100 [===================>..........] - ETA: 9:46 - loss: 0.5732 - accuracy: 0.7428 \n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 70/100 [====================>.........] - ETA: 9:27 - loss: 0.5720 - accuracy: 0.7437\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 71/100 [====================>.........] - ETA: 9:09 - loss: 0.5708 - accuracy: 0.7447\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 72/100 [====================>.........] - ETA: 8:50 - loss: 0.5717 - accuracy: 0.7439\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 73/100 [====================>.........] - ETA: 8:31 - loss: 0.5716 - accuracy: 0.7440\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 74/100 [=====================>........] - ETA: 8:12 - loss: 0.5715 - accuracy: 0.7441\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 75/100 [=====================>........] - ETA: 7:53 - loss: 0.5732 - accuracy: 0.7425\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 76/100 [=====================>........] - ETA: 7:34 - loss: 0.5740 - accuracy: 0.7418\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 77/100 [======================>.......] - ETA: 7:15 - loss: 0.5729 - accuracy: 0.7427\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 78/100 [======================>.......] - ETA: 6:56 - loss: 0.5728 - accuracy: 0.7428\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 79/100 [======================>.......] - ETA: 6:37 - loss: 0.5727 - accuracy: 0.7429\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 80/100 [=======================>......] - ETA: 6:18 - loss: 0.5734 - accuracy: 0.7422\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 81/100 [=======================>......] - ETA: 5:59 - loss: 0.5740 - accuracy: 0.7415\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 82/100 [=======================>......] - ETA: 5:40 - loss: 0.5731 - accuracy: 0.7424\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 83/100 [=======================>......] - ETA: 5:21 - loss: 0.5737 - accuracy: 0.7417\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 84/100 [========================>.....] - ETA: 5:02 - loss: 0.5758 - accuracy: 0.7396\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85/100 [========================>.....] - ETA: 4:44 - loss: 0.5764 - accuracy: 0.7390\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 86/100 [========================>.....] - ETA: 4:25 - loss: 0.5763 - accuracy: 0.7391\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 87/100 [=========================>....] - ETA: 4:06 - loss: 0.5748 - accuracy: 0.7407\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 88/100 [=========================>....] - ETA: 3:47 - loss: 0.5746 - accuracy: 0.7408\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 89/100 [=========================>....] - ETA: 3:28 - loss: 0.5745 - accuracy: 0.7409\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 90/100 [==========================>...] - ETA: 3:09 - loss: 0.5731 - accuracy: 0.7424\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 91/100 [==========================>...] - ETA: 2:50 - loss: 0.5743 - accuracy: 0.7411\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 92/100 [==========================>...] - ETA: 2:31 - loss: 0.5742 - accuracy: 0.7412\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 93/100 [==========================>...] - ETA: 2:12 - loss: 0.5729 - accuracy: 0.7426\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 94/100 [===========================>..] - ETA: 1:53 - loss: 0.5734 - accuracy: 0.7420\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 95/100 [===========================>..] - ETA: 1:34 - loss: 0.5733 - accuracy: 0.7421\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 96/100 [===========================>..] - ETA: 1:15 - loss: 0.5738 - accuracy: 0.7415\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 97/100 [============================>.] - ETA: 56s - loss: 0.5725 - accuracy: 0.7429 \n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 98/100 [============================>.] - ETA: 37s - loss: 0.5718 - accuracy: 0.7436\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      " 99/100 [============================>.] - ETA: 18s - loss: 0.5711 - accuracy: 0.7443\n",
      "Epoch 00003: accuracy did not improve from 0.87500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "100/100 [==============================] - 1926s 19s/step - loss: 0.5710 - accuracy: 0.7444 - val_loss: 0.7233 - val_accuracy: 0.5938\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.87500\n",
      "  1/100 [..............................] - ETA: 29:01 - loss: 0.4986 - accuracy: 0.8125\n",
      "Epoch 00004: accuracy did not improve from 0.87500\n",
      "  2/100 [..............................] - ETA: 29:47 - loss: 0.4322 - accuracy: 0.8750\n",
      "Epoch 00004: accuracy did not improve from 0.87500\n",
      "  3/100 [..............................] - ETA: 29:44 - loss: 0.4304 - accuracy: 0.8750\n",
      "Epoch 00004: accuracy improved from 0.87500 to 0.90625, saving model to vgg16_1.h5\n",
      "  4/100 [>.............................] - ETA: 31:56 - loss: 0.3930 - accuracy: 0.9062\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      "  5/100 [>.............................] - ETA: 31:13 - loss: 0.3973 - accuracy: 0.9000\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      "  6/100 [>.............................] - ETA: 30:42 - loss: 0.4252 - accuracy: 0.8750\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      "  7/100 [=>............................] - ETA: 30:13 - loss: 0.4575 - accuracy: 0.8482\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      "  8/100 [=>............................] - ETA: 29:46 - loss: 0.4932 - accuracy: 0.8203\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      "  9/100 [=>............................] - ETA: 29:21 - loss: 0.5018 - accuracy: 0.8125\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 10/100 [==>...........................] - ETA: 28:56 - loss: 0.5173 - accuracy: 0.8000\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 11/100 [==>...........................] - ETA: 28:35 - loss: 0.5607 - accuracy: 0.7670\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 12/100 [==>...........................] - ETA: 28:12 - loss: 0.5746 - accuracy: 0.7552\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 13/100 [==>...........................] - ETA: 27:51 - loss: 0.5621 - accuracy: 0.7644\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 14/100 [===>..........................] - ETA: 27:29 - loss: 0.5726 - accuracy: 0.7545\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 15/100 [===>..........................] - ETA: 27:08 - loss: 0.5719 - accuracy: 0.7542\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 16/100 [===>..........................] - ETA: 26:46 - loss: 0.5840 - accuracy: 0.7422\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 17/100 [====>.........................] - ETA: 26:21 - loss: 0.5942 - accuracy: 0.7316\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 18/100 [====>.........................] - ETA: 26:00 - loss: 0.5959 - accuracy: 0.7292\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 19/100 [====>.........................] - ETA: 25:31 - loss: 0.5942 - accuracy: 0.7303\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 20/100 [=====>........................] - ETA: 25:05 - loss: 0.5985 - accuracy: 0.7250\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 21/100 [=====>........................] - ETA: 24:39 - loss: 0.5996 - accuracy: 0.7232\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 22/100 [=====>........................] - ETA: 24:15 - loss: 0.5982 - accuracy: 0.7244\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 23/100 [=====>........................] - ETA: 23:53 - loss: 0.5926 - accuracy: 0.7310\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 24/100 [======>.......................] - ETA: 23:30 - loss: 0.5916 - accuracy: 0.7318\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 25/100 [======>.......................] - ETA: 23:06 - loss: 0.5867 - accuracy: 0.7375\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 26/100 [======>.......................] - ETA: 22:44 - loss: 0.5860 - accuracy: 0.7380\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 27/100 [=======>......................] - ETA: 22:26 - loss: 0.5873 - accuracy: 0.7361\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 28/100 [=======>......................] - ETA: 22:04 - loss: 0.5829 - accuracy: 0.7411\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 29/100 [=======>......................] - ETA: 21:48 - loss: 0.5806 - accuracy: 0.7435\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 30/100 [========>.....................] - ETA: 21:33 - loss: 0.5837 - accuracy: 0.7396\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 31/100 [========>.....................] - ETA: 21:12 - loss: 0.5832 - accuracy: 0.7399\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 32/100 [========>.....................] - ETA: 20:53 - loss: 0.5793 - accuracy: 0.7441\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 33/100 [========>.....................] - ETA: 20:33 - loss: 0.5806 - accuracy: 0.7424\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 34/100 [=========>....................] - ETA: 20:15 - loss: 0.5785 - accuracy: 0.7445\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 35/100 [=========>....................] - ETA: 19:57 - loss: 0.5765 - accuracy: 0.7464\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 36/100 [=========>....................] - ETA: 19:38 - loss: 0.5746 - accuracy: 0.7483\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 37/100 [==========>...................] - ETA: 19:20 - loss: 0.5759 - accuracy: 0.7466\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 38/100 [==========>...................] - ETA: 19:02 - loss: 0.5772 - accuracy: 0.7451\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 39/100 [==========>...................] - ETA: 18:43 - loss: 0.5769 - accuracy: 0.7452\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 40/100 [===========>..................] - ETA: 18:25 - loss: 0.5781 - accuracy: 0.7437\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 41/100 [===========>..................] - ETA: 18:07 - loss: 0.5778 - accuracy: 0.7439\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42/100 [===========>..................] - ETA: 17:49 - loss: 0.5806 - accuracy: 0.7411\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 43/100 [===========>..................] - ETA: 17:30 - loss: 0.5832 - accuracy: 0.7384\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 44/100 [============>.................] - ETA: 17:12 - loss: 0.5842 - accuracy: 0.7372\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 45/100 [============>.................] - ETA: 16:53 - loss: 0.5865 - accuracy: 0.7347\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 46/100 [============>.................] - ETA: 16:35 - loss: 0.5834 - accuracy: 0.7378\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 47/100 [=============>................] - ETA: 16:17 - loss: 0.5804 - accuracy: 0.7407\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 48/100 [=============>................] - ETA: 15:58 - loss: 0.5838 - accuracy: 0.7370\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 49/100 [=============>................] - ETA: 15:38 - loss: 0.5847 - accuracy: 0.7360\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 50/100 [==============>...............] - ETA: 15:17 - loss: 0.5807 - accuracy: 0.7400\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 51/100 [==============>...............] - ETA: 14:56 - loss: 0.5850 - accuracy: 0.7353\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 52/100 [==============>...............] - ETA: 14:36 - loss: 0.5824 - accuracy: 0.7380\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 53/100 [==============>...............] - ETA: 14:18 - loss: 0.5831 - accuracy: 0.7370\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 54/100 [===============>..............] - ETA: 13:59 - loss: 0.5828 - accuracy: 0.7373\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 55/100 [===============>..............] - ETA: 13:39 - loss: 0.5825 - accuracy: 0.7375\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 56/100 [===============>..............] - ETA: 13:18 - loss: 0.5821 - accuracy: 0.7377\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 57/100 [================>.............] - ETA: 12:58 - loss: 0.5850 - accuracy: 0.7346\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 58/100 [================>.............] - ETA: 12:38 - loss: 0.5867 - accuracy: 0.7328\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 59/100 [================>.............] - ETA: 12:19 - loss: 0.5863 - accuracy: 0.7331\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 60/100 [=================>............] - ETA: 12:00 - loss: 0.5859 - accuracy: 0.7333\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 61/100 [=================>............] - ETA: 11:42 - loss: 0.5846 - accuracy: 0.7346\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 62/100 [=================>............] - ETA: 11:23 - loss: 0.5824 - accuracy: 0.7369\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 63/100 [=================>............] - ETA: 11:04 - loss: 0.5803 - accuracy: 0.7391\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 64/100 [==================>...........] - ETA: 10:46 - loss: 0.5810 - accuracy: 0.7383\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 65/100 [==================>...........] - ETA: 10:27 - loss: 0.5798 - accuracy: 0.7394\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 66/100 [==================>...........] - ETA: 10:09 - loss: 0.5786 - accuracy: 0.7405\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 67/100 [===================>..........] - ETA: 9:51 - loss: 0.5784 - accuracy: 0.7407 \n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 68/100 [===================>..........] - ETA: 9:32 - loss: 0.5773 - accuracy: 0.7417\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 69/100 [===================>..........] - ETA: 9:14 - loss: 0.5798 - accuracy: 0.7391\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 70/100 [====================>.........] - ETA: 8:56 - loss: 0.5814 - accuracy: 0.7375\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 71/100 [====================>.........] - ETA: 8:38 - loss: 0.5812 - accuracy: 0.7377\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 72/100 [====================>.........] - ETA: 8:21 - loss: 0.5827 - accuracy: 0.7361\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 73/100 [====================>.........] - ETA: 8:04 - loss: 0.5824 - accuracy: 0.7363\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 74/100 [=====================>........] - ETA: 7:46 - loss: 0.5804 - accuracy: 0.7382\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 75/100 [=====================>........] - ETA: 7:29 - loss: 0.5811 - accuracy: 0.7375\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 76/100 [=====================>........] - ETA: 7:11 - loss: 0.5808 - accuracy: 0.7377\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 77/100 [======================>.......] - ETA: 6:54 - loss: 0.5806 - accuracy: 0.7378\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 78/100 [======================>.......] - ETA: 6:36 - loss: 0.5795 - accuracy: 0.7388\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 79/100 [======================>.......] - ETA: 6:18 - loss: 0.5810 - accuracy: 0.7373\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 80/100 [=======================>......] - ETA: 6:00 - loss: 0.5807 - accuracy: 0.7375\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 81/100 [=======================>......] - ETA: 5:42 - loss: 0.5805 - accuracy: 0.7377\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 82/100 [=======================>......] - ETA: 5:24 - loss: 0.5811 - accuracy: 0.7370\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 83/100 [=======================>......] - ETA: 5:07 - loss: 0.5816 - accuracy: 0.7364\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 84/100 [========================>.....] - ETA: 4:49 - loss: 0.5807 - accuracy: 0.7374\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 85/100 [========================>.....] - ETA: 4:30 - loss: 0.5797 - accuracy: 0.7382\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 86/100 [========================>.....] - ETA: 4:13 - loss: 0.5780 - accuracy: 0.7398\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 87/100 [=========================>....] - ETA: 3:55 - loss: 0.5778 - accuracy: 0.7399\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 88/100 [=========================>....] - ETA: 3:37 - loss: 0.5776 - accuracy: 0.7401\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 89/100 [=========================>....] - ETA: 3:19 - loss: 0.5782 - accuracy: 0.7395\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 90/100 [==========================>...] - ETA: 3:01 - loss: 0.5780 - accuracy: 0.7396\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 91/100 [==========================>...] - ETA: 2:43 - loss: 0.5823 - accuracy: 0.7356\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 92/100 [==========================>...] - ETA: 2:24 - loss: 0.5835 - accuracy: 0.7344\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 93/100 [==========================>...] - ETA: 2:06 - loss: 0.5826 - accuracy: 0.7352\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 94/100 [===========================>..] - ETA: 1:48 - loss: 0.5824 - accuracy: 0.7354\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 95/100 [===========================>..] - ETA: 1:30 - loss: 0.5829 - accuracy: 0.7349\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 96/100 [===========================>..] - ETA: 1:12 - loss: 0.5840 - accuracy: 0.7337\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 97/100 [============================>.] - ETA: 54s - loss: 0.5844 - accuracy: 0.7332 \n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 98/100 [============================>.] - ETA: 36s - loss: 0.5842 - accuracy: 0.7334\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      " 99/100 [============================>.] - ETA: 18s - loss: 0.5834 - accuracy: 0.7342\n",
      "Epoch 00004: accuracy did not improve from 0.90625\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "100/100 [==============================] - 1870s 19s/step - loss: 0.5832 - accuracy: 0.7344 - val_loss: 0.7120 - val_accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  1/100 [..............................] - ETA: 31:10 - loss: 0.4468 - accuracy: 0.8750\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  2/100 [..............................] - ETA: 30:50 - loss: 0.5057 - accuracy: 0.8125\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  3/100 [..............................] - ETA: 27:24 - loss: 0.5057 - accuracy: 0.8125\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  4/100 [>.............................] - ETA: 24:34 - loss: 0.5352 - accuracy: 0.7812\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  5/100 [>.............................] - ETA: 23:00 - loss: 0.4935 - accuracy: 0.8250\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  6/100 [>.............................] - ETA: 22:12 - loss: 0.4851 - accuracy: 0.8333\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  7/100 [=>............................] - ETA: 21:37 - loss: 0.4964 - accuracy: 0.8214\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  8/100 [=>............................] - ETA: 21:04 - loss: 0.4814 - accuracy: 0.8359\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "  9/100 [=>............................] - ETA: 20:42 - loss: 0.4833 - accuracy: 0.8333\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 10/100 [==>...........................] - ETA: 20:18 - loss: 0.4978 - accuracy: 0.8188\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 11/100 [==>...........................] - ETA: 19:57 - loss: 0.4915 - accuracy: 0.8239\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 12/100 [==>...........................] - ETA: 19:38 - loss: 0.5146 - accuracy: 0.8021\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 13/100 [==>...........................] - ETA: 19:22 - loss: 0.5182 - accuracy: 0.7981\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 14/100 [===>..........................] - ETA: 19:05 - loss: 0.5214 - accuracy: 0.7946\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 15/100 [===>..........................] - ETA: 18:54 - loss: 0.5194 - accuracy: 0.7958\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 16/100 [===>..........................] - ETA: 18:36 - loss: 0.5176 - accuracy: 0.7969\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 17/100 [====>.........................] - ETA: 18:20 - loss: 0.5245 - accuracy: 0.7904\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 18/100 [====>.........................] - ETA: 18:05 - loss: 0.5267 - accuracy: 0.7882\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 19/100 [====>.........................] - ETA: 17:50 - loss: 0.5247 - accuracy: 0.7895\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 20/100 [=====>........................] - ETA: 17:43 - loss: 0.5229 - accuracy: 0.7906\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 21/100 [=====>........................] - ETA: 17:32 - loss: 0.5212 - accuracy: 0.7917\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 22/100 [=====>........................] - ETA: 17:21 - loss: 0.5127 - accuracy: 0.7983\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 23/100 [=====>........................] - ETA: 17:05 - loss: 0.5116 - accuracy: 0.7989\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 24/100 [======>.......................] - ETA: 16:52 - loss: 0.5172 - accuracy: 0.7943\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 25/100 [======>.......................] - ETA: 16:43 - loss: 0.5191 - accuracy: 0.7925\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 26/100 [======>.......................] - ETA: 16:31 - loss: 0.5178 - accuracy: 0.7933\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 27/100 [=======>......................] - ETA: 16:15 - loss: 0.5196 - accuracy: 0.7917\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 28/100 [=======>......................] - ETA: 16:00 - loss: 0.5213 - accuracy: 0.7902\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 29/100 [=======>......................] - ETA: 15:47 - loss: 0.5287 - accuracy: 0.7845\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 30/100 [========>.....................] - ETA: 15:32 - loss: 0.5355 - accuracy: 0.7792\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 31/100 [========>.....................] - ETA: 15:20 - loss: 0.5495 - accuracy: 0.7681\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 32/100 [========>.....................] - ETA: 15:05 - loss: 0.5475 - accuracy: 0.7695\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 33/100 [========>.....................] - ETA: 14:52 - loss: 0.5503 - accuracy: 0.7670\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 34/100 [=========>....................] - ETA: 14:38 - loss: 0.5549 - accuracy: 0.7629\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 35/100 [=========>....................] - ETA: 14:24 - loss: 0.5551 - accuracy: 0.7625\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 36/100 [=========>....................] - ETA: 14:12 - loss: 0.5571 - accuracy: 0.7604\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 37/100 [==========>...................] - ETA: 13:58 - loss: 0.5555 - accuracy: 0.7618\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 38/100 [==========>...................] - ETA: 13:44 - loss: 0.5557 - accuracy: 0.7615\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 39/100 [==========>...................] - ETA: 13:30 - loss: 0.5512 - accuracy: 0.7660\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 40/100 [===========>..................] - ETA: 13:16 - loss: 0.5499 - accuracy: 0.7672\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 41/100 [===========>..................] - ETA: 13:02 - loss: 0.5503 - accuracy: 0.7668\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 42/100 [===========>..................] - ETA: 12:48 - loss: 0.5535 - accuracy: 0.7634\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 43/100 [===========>..................] - ETA: 12:33 - loss: 0.5509 - accuracy: 0.7660\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 44/100 [============>.................] - ETA: 12:19 - loss: 0.5512 - accuracy: 0.7656\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 45/100 [============>.................] - ETA: 12:05 - loss: 0.5489 - accuracy: 0.7681\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 46/100 [============>.................] - ETA: 11:53 - loss: 0.5492 - accuracy: 0.7677\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 47/100 [=============>................] - ETA: 11:41 - loss: 0.5495 - accuracy: 0.7673\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 48/100 [=============>................] - ETA: 11:28 - loss: 0.5498 - accuracy: 0.7669\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 49/100 [=============>................] - ETA: 11:15 - loss: 0.5551 - accuracy: 0.7615\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 50/100 [==============>...............] - ETA: 11:02 - loss: 0.5552 - accuracy: 0.7613\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 51/100 [==============>...............] - ETA: 10:49 - loss: 0.5614 - accuracy: 0.7549\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 52/100 [==============>...............] - ETA: 10:35 - loss: 0.5580 - accuracy: 0.7584\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 53/100 [==============>...............] - ETA: 10:22 - loss: 0.5558 - accuracy: 0.7606\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 54/100 [===============>..............] - ETA: 10:09 - loss: 0.5526 - accuracy: 0.7639\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 55/100 [===============>..............] - ETA: 9:55 - loss: 0.5517 - accuracy: 0.7648 \n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 56/100 [===============>..............] - ETA: 9:42 - loss: 0.5530 - accuracy: 0.7634\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 57/100 [================>.............] - ETA: 9:28 - loss: 0.5565 - accuracy: 0.7599\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 58/100 [================>.............] - ETA: 9:15 - loss: 0.5566 - accuracy: 0.7597\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59/100 [================>.............] - ETA: 9:02 - loss: 0.5536 - accuracy: 0.7627\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 60/100 [=================>............] - ETA: 8:48 - loss: 0.5516 - accuracy: 0.7646\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 61/100 [=================>............] - ETA: 8:34 - loss: 0.5549 - accuracy: 0.7613\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 62/100 [=================>............] - ETA: 8:21 - loss: 0.5551 - accuracy: 0.7611\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 63/100 [=================>............] - ETA: 8:07 - loss: 0.5582 - accuracy: 0.7579\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 64/100 [==================>...........] - ETA: 7:54 - loss: 0.5593 - accuracy: 0.7568\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 65/100 [==================>...........] - ETA: 7:41 - loss: 0.5564 - accuracy: 0.7596\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 66/100 [==================>...........] - ETA: 7:28 - loss: 0.5536 - accuracy: 0.7623\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 67/100 [===================>..........] - ETA: 7:15 - loss: 0.5557 - accuracy: 0.7603\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 68/100 [===================>..........] - ETA: 7:02 - loss: 0.5539 - accuracy: 0.7619\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 69/100 [===================>..........] - ETA: 6:48 - loss: 0.5521 - accuracy: 0.7636\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 70/100 [====================>.........] - ETA: 6:36 - loss: 0.5532 - accuracy: 0.7625\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 71/100 [====================>.........] - ETA: 6:23 - loss: 0.5562 - accuracy: 0.7597\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 72/100 [====================>.........] - ETA: 6:10 - loss: 0.5562 - accuracy: 0.7595\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 73/100 [====================>.........] - ETA: 5:57 - loss: 0.5591 - accuracy: 0.7568\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 74/100 [=====================>........] - ETA: 5:44 - loss: 0.5592 - accuracy: 0.7568\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 75/100 [=====================>........] - ETA: 5:31 - loss: 0.5583 - accuracy: 0.7575\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 76/100 [=====================>........] - ETA: 5:17 - loss: 0.5619 - accuracy: 0.7541\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 77/100 [======================>.......] - ETA: 5:04 - loss: 0.5610 - accuracy: 0.7549\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 78/100 [======================>.......] - ETA: 4:51 - loss: 0.5611 - accuracy: 0.7548\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 79/100 [======================>.......] - ETA: 4:38 - loss: 0.5619 - accuracy: 0.7540\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 80/100 [=======================>......] - ETA: 4:25 - loss: 0.5603 - accuracy: 0.7555\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 81/100 [=======================>......] - ETA: 4:11 - loss: 0.5587 - accuracy: 0.7569\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 82/100 [=======================>......] - ETA: 3:58 - loss: 0.5596 - accuracy: 0.7561\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 83/100 [=======================>......] - ETA: 3:45 - loss: 0.5588 - accuracy: 0.7568\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 84/100 [========================>.....] - ETA: 3:31 - loss: 0.5628 - accuracy: 0.7530\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 85/100 [========================>.....] - ETA: 3:18 - loss: 0.5620 - accuracy: 0.7537\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 86/100 [========================>.....] - ETA: 3:05 - loss: 0.5635 - accuracy: 0.7522\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 87/100 [=========================>....] - ETA: 2:52 - loss: 0.5628 - accuracy: 0.7529\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 88/100 [=========================>....] - ETA: 2:39 - loss: 0.5628 - accuracy: 0.7528\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 89/100 [=========================>....] - ETA: 2:25 - loss: 0.5649 - accuracy: 0.7507\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 90/100 [==========================>...] - ETA: 2:12 - loss: 0.5649 - accuracy: 0.7507\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 91/100 [==========================>...] - ETA: 1:59 - loss: 0.5649 - accuracy: 0.7507\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 92/100 [==========================>...] - ETA: 1:46 - loss: 0.5642 - accuracy: 0.7514\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 93/100 [==========================>...] - ETA: 1:32 - loss: 0.5655 - accuracy: 0.7500\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 94/100 [===========================>..] - ETA: 1:19 - loss: 0.5661 - accuracy: 0.7493\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 95/100 [===========================>..] - ETA: 1:06 - loss: 0.5674 - accuracy: 0.7480\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 96/100 [===========================>..] - ETA: 53s - loss: 0.5680 - accuracy: 0.7474 \n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 97/100 [============================>.] - ETA: 39s - loss: 0.5692 - accuracy: 0.7461\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 98/100 [============================>.] - ETA: 26s - loss: 0.5704 - accuracy: 0.7449\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      " 99/100 [============================>.] - ETA: 13s - loss: 0.5703 - accuracy: 0.7449\n",
      "Epoch 00005: accuracy did not improve from 0.90625\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "100/100 [==============================] - 1367s 14s/step - loss: 0.5703 - accuracy: 0.7450 - val_loss: 0.7097 - val_accuracy: 0.5938\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  1/100 [..............................] - ETA: 21:31 - loss: 0.5653 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  2/100 [..............................] - ETA: 21:23 - loss: 0.6515 - accuracy: 0.6562\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  3/100 [..............................] - ETA: 21:07 - loss: 0.6229 - accuracy: 0.6875\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  4/100 [>.............................] - ETA: 21:03 - loss: 0.6087 - accuracy: 0.7031\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  5/100 [>.............................] - ETA: 20:56 - loss: 0.6002 - accuracy: 0.7125\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  6/100 [>.............................] - ETA: 20:53 - loss: 0.6132 - accuracy: 0.6979\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  7/100 [=>............................] - ETA: 20:44 - loss: 0.5828 - accuracy: 0.7321\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  8/100 [=>............................] - ETA: 20:35 - loss: 0.5808 - accuracy: 0.7344\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "  9/100 [=>............................] - ETA: 20:20 - loss: 0.5792 - accuracy: 0.7361\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 10/100 [==>...........................] - ETA: 20:10 - loss: 0.5724 - accuracy: 0.7437\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 11/100 [==>...........................] - ETA: 20:00 - loss: 0.5617 - accuracy: 0.7557\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 12/100 [==>...........................] - ETA: 19:48 - loss: 0.5527 - accuracy: 0.7656\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 13/100 [==>...........................] - ETA: 19:35 - loss: 0.5581 - accuracy: 0.7596\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 14/100 [===>..........................] - ETA: 19:21 - loss: 0.5668 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 15/100 [===>..........................] - ETA: 19:07 - loss: 0.5706 - accuracy: 0.7458\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 16/100 [===>..........................] - ETA: 18:51 - loss: 0.5666 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/100 [====>.........................] - ETA: 18:37 - loss: 0.5665 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 18/100 [====>.........................] - ETA: 18:31 - loss: 0.5664 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 19/100 [====>.........................] - ETA: 18:19 - loss: 0.5569 - accuracy: 0.7599\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 20/100 [=====>........................] - ETA: 18:12 - loss: 0.5602 - accuracy: 0.7563\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 21/100 [=====>........................] - ETA: 18:03 - loss: 0.5604 - accuracy: 0.7560\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 22/100 [=====>........................] - ETA: 17:55 - loss: 0.5549 - accuracy: 0.7614\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 23/100 [=====>........................] - ETA: 17:44 - loss: 0.5499 - accuracy: 0.7663\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 24/100 [======>.......................] - ETA: 17:35 - loss: 0.5504 - accuracy: 0.7656\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 25/100 [======>.......................] - ETA: 17:26 - loss: 0.5509 - accuracy: 0.7650\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 26/100 [======>.......................] - ETA: 17:16 - loss: 0.5488 - accuracy: 0.7668\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 27/100 [=======>......................] - ETA: 17:08 - loss: 0.5469 - accuracy: 0.7685\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 28/100 [=======>......................] - ETA: 17:01 - loss: 0.5596 - accuracy: 0.7567\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 29/100 [=======>......................] - ETA: 16:53 - loss: 0.5620 - accuracy: 0.7543\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 30/100 [========>.....................] - ETA: 16:41 - loss: 0.5552 - accuracy: 0.7604\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 31/100 [========>.....................] - ETA: 16:30 - loss: 0.5532 - accuracy: 0.7621\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 32/100 [========>.....................] - ETA: 16:15 - loss: 0.5535 - accuracy: 0.7617\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 33/100 [========>.....................] - ETA: 16:02 - loss: 0.5580 - accuracy: 0.7576\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 34/100 [=========>....................] - ETA: 15:51 - loss: 0.5623 - accuracy: 0.7537\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 35/100 [=========>....................] - ETA: 15:37 - loss: 0.5563 - accuracy: 0.7589\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 36/100 [=========>....................] - ETA: 15:23 - loss: 0.5545 - accuracy: 0.7604\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 37/100 [==========>...................] - ETA: 15:12 - loss: 0.5547 - accuracy: 0.7601\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 38/100 [==========>...................] - ETA: 14:59 - loss: 0.5549 - accuracy: 0.7599\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 39/100 [==========>...................] - ETA: 14:45 - loss: 0.5569 - accuracy: 0.7580\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 40/100 [===========>..................] - ETA: 14:30 - loss: 0.5517 - accuracy: 0.7625\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 41/100 [===========>..................] - ETA: 14:15 - loss: 0.5502 - accuracy: 0.7637\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 42/100 [===========>..................] - ETA: 13:59 - loss: 0.5522 - accuracy: 0.7619\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 43/100 [===========>..................] - ETA: 13:44 - loss: 0.5490 - accuracy: 0.7645\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 44/100 [============>.................] - ETA: 13:27 - loss: 0.5494 - accuracy: 0.7642\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 45/100 [============>.................] - ETA: 13:11 - loss: 0.5514 - accuracy: 0.7625\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 46/100 [============>.................] - ETA: 12:56 - loss: 0.5549 - accuracy: 0.7595\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 47/100 [=============>................] - ETA: 12:43 - loss: 0.5583 - accuracy: 0.7566\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 48/100 [=============>................] - ETA: 12:27 - loss: 0.5584 - accuracy: 0.7565\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 49/100 [=============>................] - ETA: 12:13 - loss: 0.5570 - accuracy: 0.7577\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 50/100 [==============>...............] - ETA: 11:58 - loss: 0.5600 - accuracy: 0.7550\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 51/100 [==============>...............] - ETA: 11:44 - loss: 0.5615 - accuracy: 0.7537\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 52/100 [==============>...............] - ETA: 11:30 - loss: 0.5615 - accuracy: 0.7536\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 53/100 [==============>...............] - ETA: 11:15 - loss: 0.5602 - accuracy: 0.7547\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 54/100 [===============>..............] - ETA: 11:01 - loss: 0.5615 - accuracy: 0.7535\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 55/100 [===============>..............] - ETA: 10:47 - loss: 0.5590 - accuracy: 0.7557\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 56/100 [===============>..............] - ETA: 10:33 - loss: 0.5603 - accuracy: 0.7545\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 57/100 [================>.............] - ETA: 10:18 - loss: 0.5627 - accuracy: 0.7522\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 58/100 [================>.............] - ETA: 10:04 - loss: 0.5651 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 59/100 [================>.............] - ETA: 9:53 - loss: 0.5639 - accuracy: 0.7511 \n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 60/100 [=================>............] - ETA: 9:41 - loss: 0.5671 - accuracy: 0.7479\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 61/100 [=================>............] - ETA: 9:28 - loss: 0.5671 - accuracy: 0.7480\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 62/100 [=================>............] - ETA: 9:18 - loss: 0.5680 - accuracy: 0.7470\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 63/100 [=================>............] - ETA: 9:05 - loss: 0.5670 - accuracy: 0.7480\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 64/100 [==================>...........] - ETA: 8:51 - loss: 0.5679 - accuracy: 0.7471\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 65/100 [==================>...........] - ETA: 8:36 - loss: 0.5669 - accuracy: 0.7481\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 66/100 [==================>...........] - ETA: 8:23 - loss: 0.5649 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 67/100 [===================>..........] - ETA: 8:08 - loss: 0.5649 - accuracy: 0.7500\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 68/100 [===================>..........] - ETA: 7:55 - loss: 0.5667 - accuracy: 0.7482\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 69/100 [===================>..........] - ETA: 7:40 - loss: 0.5640 - accuracy: 0.7509\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 70/100 [====================>.........] - ETA: 7:26 - loss: 0.5623 - accuracy: 0.7527\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 71/100 [====================>.........] - ETA: 7:11 - loss: 0.5605 - accuracy: 0.7544\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 72/100 [====================>.........] - ETA: 6:56 - loss: 0.5614 - accuracy: 0.7535\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 73/100 [====================>.........] - ETA: 6:41 - loss: 0.5615 - accuracy: 0.7534\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 74/100 [=====================>........] - ETA: 6:27 - loss: 0.5598 - accuracy: 0.7551\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 75/100 [=====================>........] - ETA: 6:12 - loss: 0.5572 - accuracy: 0.7575\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76/100 [=====================>........] - ETA: 5:57 - loss: 0.5582 - accuracy: 0.7566\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 77/100 [======================>.......] - ETA: 5:43 - loss: 0.5608 - accuracy: 0.7541\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 78/100 [======================>.......] - ETA: 5:28 - loss: 0.5617 - accuracy: 0.7532\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 79/100 [======================>.......] - ETA: 5:13 - loss: 0.5591 - accuracy: 0.7555\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 80/100 [=======================>......] - ETA: 4:58 - loss: 0.5609 - accuracy: 0.7539\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 81/100 [=======================>......] - ETA: 4:43 - loss: 0.5617 - accuracy: 0.7531\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 82/100 [=======================>......] - ETA: 4:28 - loss: 0.5617 - accuracy: 0.7530\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 83/100 [=======================>......] - ETA: 4:13 - loss: 0.5601 - accuracy: 0.7545\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 84/100 [========================>.....] - ETA: 3:58 - loss: 0.5585 - accuracy: 0.7560\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 85/100 [========================>.....] - ETA: 3:43 - loss: 0.5569 - accuracy: 0.7574\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 86/100 [========================>.....] - ETA: 3:28 - loss: 0.5586 - accuracy: 0.7558\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 87/100 [=========================>....] - ETA: 3:13 - loss: 0.5595 - accuracy: 0.7550\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 88/100 [=========================>....] - ETA: 2:58 - loss: 0.5595 - accuracy: 0.7550\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 89/100 [=========================>....] - ETA: 2:43 - loss: 0.5603 - accuracy: 0.7542\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 90/100 [==========================>...] - ETA: 2:28 - loss: 0.5604 - accuracy: 0.7542\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 91/100 [==========================>...] - ETA: 2:13 - loss: 0.5604 - accuracy: 0.7541\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 92/100 [==========================>...] - ETA: 1:58 - loss: 0.5604 - accuracy: 0.7541\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 93/100 [==========================>...] - ETA: 1:43 - loss: 0.5604 - accuracy: 0.7540\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 94/100 [===========================>..] - ETA: 1:29 - loss: 0.5612 - accuracy: 0.7533\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 95/100 [===========================>..] - ETA: 1:14 - loss: 0.5620 - accuracy: 0.7526\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 96/100 [===========================>..] - ETA: 59s - loss: 0.5613 - accuracy: 0.7533 \n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 97/100 [============================>.] - ETA: 44s - loss: 0.5620 - accuracy: 0.7526\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 98/100 [============================>.] - ETA: 29s - loss: 0.5620 - accuracy: 0.7526\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      " 99/100 [============================>.] - ETA: 14s - loss: 0.5634 - accuracy: 0.7513\n",
      "Epoch 00006: accuracy did not improve from 0.90625\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "100/100 [==============================] - 1527s 15s/step - loss: 0.5634 - accuracy: 0.7513 - val_loss: 0.7330 - val_accuracy: 0.5938\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  1/100 [..............................] - ETA: 22:58 - loss: 0.6306 - accuracy: 0.6875\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  2/100 [..............................] - ETA: 22:36 - loss: 0.5965 - accuracy: 0.7188\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  3/100 [..............................] - ETA: 22:36 - loss: 0.5628 - accuracy: 0.7500\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  4/100 [>.............................] - ETA: 22:33 - loss: 0.5627 - accuracy: 0.7500\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  5/100 [>.............................] - ETA: 22:33 - loss: 0.5892 - accuracy: 0.7250\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  6/100 [>.............................] - ETA: 22:22 - loss: 0.5957 - accuracy: 0.7188\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  7/100 [=>............................] - ETA: 22:09 - loss: 0.6188 - accuracy: 0.6964\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  8/100 [=>............................] - ETA: 21:51 - loss: 0.6198 - accuracy: 0.6953\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "  9/100 [=>............................] - ETA: 21:38 - loss: 0.5995 - accuracy: 0.7153\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 10/100 [==>...........................] - ETA: 21:20 - loss: 0.5959 - accuracy: 0.7188\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 11/100 [==>...........................] - ETA: 21:03 - loss: 0.5986 - accuracy: 0.7159\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 12/100 [==>...........................] - ETA: 20:49 - loss: 0.5802 - accuracy: 0.7344\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 13/100 [==>...........................] - ETA: 20:35 - loss: 0.5742 - accuracy: 0.7404\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 14/100 [===>..........................] - ETA: 20:20 - loss: 0.5690 - accuracy: 0.7455\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 15/100 [===>..........................] - ETA: 20:08 - loss: 0.5852 - accuracy: 0.7292\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 16/100 [===>..........................] - ETA: 19:54 - loss: 0.5954 - accuracy: 0.7188\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 17/100 [====>.........................] - ETA: 19:42 - loss: 0.6044 - accuracy: 0.7096\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 18/100 [====>.........................] - ETA: 19:30 - loss: 0.6055 - accuracy: 0.7083\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 19/100 [====>.........................] - ETA: 19:14 - loss: 0.5970 - accuracy: 0.7171\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 20/100 [=====>........................] - ETA: 19:02 - loss: 0.6014 - accuracy: 0.7125\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 21/100 [=====>........................] - ETA: 18:53 - loss: 0.5912 - accuracy: 0.7232\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 22/100 [=====>........................] - ETA: 18:42 - loss: 0.5873 - accuracy: 0.7273\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 23/100 [=====>........................] - ETA: 18:26 - loss: 0.5889 - accuracy: 0.7255\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 24/100 [======>.......................] - ETA: 18:13 - loss: 0.5780 - accuracy: 0.7370\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 25/100 [======>.......................] - ETA: 18:00 - loss: 0.5751 - accuracy: 0.7400\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 26/100 [======>.......................] - ETA: 17:46 - loss: 0.5770 - accuracy: 0.7380\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 27/100 [=======>......................] - ETA: 17:33 - loss: 0.5742 - accuracy: 0.7407\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 28/100 [=======>......................] - ETA: 17:21 - loss: 0.5717 - accuracy: 0.7433\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 29/100 [=======>......................] - ETA: 17:10 - loss: 0.5714 - accuracy: 0.7435\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 30/100 [========>.....................] - ETA: 16:57 - loss: 0.5732 - accuracy: 0.7417\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 31/100 [========>.....................] - ETA: 16:43 - loss: 0.5810 - accuracy: 0.7339\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 32/100 [========>.....................] - ETA: 16:29 - loss: 0.5844 - accuracy: 0.7305\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 33/100 [========>.....................] - ETA: 16:14 - loss: 0.5837 - accuracy: 0.7311\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/100 [=========>....................] - ETA: 16:00 - loss: 0.5795 - accuracy: 0.7353\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 35/100 [=========>....................] - ETA: 15:46 - loss: 0.5772 - accuracy: 0.7375\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 36/100 [=========>....................] - ETA: 15:34 - loss: 0.5786 - accuracy: 0.7361\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 37/100 [==========>...................] - ETA: 15:20 - loss: 0.5798 - accuracy: 0.7348\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 38/100 [==========>...................] - ETA: 15:07 - loss: 0.5827 - accuracy: 0.7319\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 39/100 [==========>...................] - ETA: 14:51 - loss: 0.5871 - accuracy: 0.7276\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 40/100 [===========>..................] - ETA: 14:38 - loss: 0.5881 - accuracy: 0.7266\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 41/100 [===========>..................] - ETA: 14:23 - loss: 0.5920 - accuracy: 0.7226\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 42/100 [===========>..................] - ETA: 14:08 - loss: 0.5913 - accuracy: 0.7232\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 43/100 [===========>..................] - ETA: 13:54 - loss: 0.5935 - accuracy: 0.7209\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 44/100 [============>.................] - ETA: 13:40 - loss: 0.5929 - accuracy: 0.7216\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 45/100 [============>.................] - ETA: 13:26 - loss: 0.5896 - accuracy: 0.7250\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 46/100 [============>.................] - ETA: 13:11 - loss: 0.5890 - accuracy: 0.7255\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 47/100 [=============>................] - ETA: 12:56 - loss: 0.5860 - accuracy: 0.7287\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 48/100 [=============>................] - ETA: 12:41 - loss: 0.5856 - accuracy: 0.7292\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 49/100 [=============>................] - ETA: 12:28 - loss: 0.5803 - accuracy: 0.7347\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 50/100 [==============>...............] - ETA: 12:13 - loss: 0.5812 - accuracy: 0.7337\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 51/100 [==============>...............] - ETA: 11:59 - loss: 0.5809 - accuracy: 0.7341\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 52/100 [==============>...............] - ETA: 11:44 - loss: 0.5817 - accuracy: 0.7332\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 53/100 [==============>...............] - ETA: 11:30 - loss: 0.5802 - accuracy: 0.7347\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 54/100 [===============>..............] - ETA: 11:15 - loss: 0.5833 - accuracy: 0.7315\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 55/100 [===============>..............] - ETA: 11:00 - loss: 0.5863 - accuracy: 0.7284\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 56/100 [===============>..............] - ETA: 10:45 - loss: 0.5870 - accuracy: 0.7277\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 57/100 [================>.............] - ETA: 10:30 - loss: 0.5877 - accuracy: 0.7270\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 58/100 [================>.............] - ETA: 10:17 - loss: 0.5893 - accuracy: 0.7252\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 59/100 [================>.............] - ETA: 10:03 - loss: 0.5869 - accuracy: 0.7278\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 60/100 [=================>............] - ETA: 9:50 - loss: 0.5865 - accuracy: 0.7281 \n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 61/100 [=================>............] - ETA: 9:36 - loss: 0.5881 - accuracy: 0.7264\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 62/100 [=================>............] - ETA: 9:22 - loss: 0.5877 - accuracy: 0.7268\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 63/100 [=================>............] - ETA: 9:08 - loss: 0.5911 - accuracy: 0.7232\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 64/100 [==================>...........] - ETA: 8:55 - loss: 0.5944 - accuracy: 0.7197\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 65/100 [==================>...........] - ETA: 8:42 - loss: 0.5940 - accuracy: 0.7202\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 66/100 [==================>...........] - ETA: 8:28 - loss: 0.5927 - accuracy: 0.7216\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 67/100 [===================>..........] - ETA: 8:14 - loss: 0.5922 - accuracy: 0.7220\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 68/100 [===================>..........] - ETA: 7:59 - loss: 0.5919 - accuracy: 0.7224\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 69/100 [===================>..........] - ETA: 7:44 - loss: 0.5915 - accuracy: 0.7228\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 70/100 [====================>.........] - ETA: 7:29 - loss: 0.5911 - accuracy: 0.7232\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 71/100 [====================>.........] - ETA: 7:13 - loss: 0.5884 - accuracy: 0.7262\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 72/100 [====================>.........] - ETA: 6:58 - loss: 0.5881 - accuracy: 0.7266\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 73/100 [====================>.........] - ETA: 6:44 - loss: 0.5893 - accuracy: 0.7252\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 74/100 [=====================>........] - ETA: 6:29 - loss: 0.5898 - accuracy: 0.7247\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 75/100 [=====================>........] - ETA: 6:14 - loss: 0.5902 - accuracy: 0.7242\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 76/100 [=====================>........] - ETA: 5:59 - loss: 0.5899 - accuracy: 0.7245\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 77/100 [======================>.......] - ETA: 5:45 - loss: 0.5881 - accuracy: 0.7265\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 78/100 [======================>.......] - ETA: 5:30 - loss: 0.5856 - accuracy: 0.7292\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 79/100 [======================>.......] - ETA: 5:15 - loss: 0.5853 - accuracy: 0.7294\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 80/100 [=======================>......] - ETA: 5:00 - loss: 0.5843 - accuracy: 0.7305\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 81/100 [=======================>......] - ETA: 4:45 - loss: 0.5855 - accuracy: 0.7292\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 82/100 [=======================>......] - ETA: 4:30 - loss: 0.5867 - accuracy: 0.7279\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 83/100 [=======================>......] - ETA: 4:15 - loss: 0.5850 - accuracy: 0.7297\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 84/100 [========================>.....] - ETA: 3:59 - loss: 0.5840 - accuracy: 0.7307\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 85/100 [========================>.....] - ETA: 3:45 - loss: 0.5823 - accuracy: 0.7324\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 86/100 [========================>.....] - ETA: 3:30 - loss: 0.5814 - accuracy: 0.7333\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 87/100 [=========================>....] - ETA: 3:15 - loss: 0.5790 - accuracy: 0.7356\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 88/100 [=========================>....] - ETA: 3:00 - loss: 0.5795 - accuracy: 0.7351\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 89/100 [=========================>....] - ETA: 2:45 - loss: 0.5771 - accuracy: 0.7374\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 90/100 [==========================>...] - ETA: 2:30 - loss: 0.5754 - accuracy: 0.7389\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 91/100 [==========================>...] - ETA: 2:15 - loss: 0.5745 - accuracy: 0.7397\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 92/100 [==========================>...] - ETA: 2:00 - loss: 0.5751 - accuracy: 0.7391\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93/100 [==========================>...] - ETA: 1:45 - loss: 0.5742 - accuracy: 0.7399\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 94/100 [===========================>..] - ETA: 1:30 - loss: 0.5757 - accuracy: 0.7387\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 95/100 [===========================>..] - ETA: 1:15 - loss: 0.5740 - accuracy: 0.7401\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 96/100 [===========================>..] - ETA: 1:00 - loss: 0.5739 - accuracy: 0.7402\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 97/100 [============================>.] - ETA: 45s - loss: 0.5762 - accuracy: 0.7384 \n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 98/100 [============================>.] - ETA: 30s - loss: 0.5745 - accuracy: 0.7398\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      " 99/100 [============================>.] - ETA: 15s - loss: 0.5752 - accuracy: 0.7393\n",
      "Epoch 00007: accuracy did not improve from 0.90625\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "100/100 [==============================] - 1553s 16s/step - loss: 0.5743 - accuracy: 0.7400 - val_loss: 0.7619 - val_accuracy: 0.5938\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  1/100 [..............................] - ETA: 25:09 - loss: 0.4859 - accuracy: 0.8125\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  2/100 [..............................] - ETA: 25:27 - loss: 0.6045 - accuracy: 0.7188\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  3/100 [..............................] - ETA: 25:56 - loss: 0.6437 - accuracy: 0.6875\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  4/100 [>.............................] - ETA: 26:30 - loss: 0.5850 - accuracy: 0.7344\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  5/100 [>.............................] - ETA: 26:47 - loss: 0.6116 - accuracy: 0.7125\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  6/100 [>.............................] - ETA: 27:29 - loss: 0.5783 - accuracy: 0.7396\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  7/100 [=>............................] - ETA: 27:25 - loss: 0.5977 - accuracy: 0.7232\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  8/100 [=>............................] - ETA: 27:33 - loss: 0.5841 - accuracy: 0.7344\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      "  9/100 [=>............................] - ETA: 27:19 - loss: 0.5654 - accuracy: 0.7500\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 10/100 [==>...........................] - ETA: 26:53 - loss: 0.5725 - accuracy: 0.7437\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 11/100 [==>...........................] - ETA: 26:33 - loss: 0.5650 - accuracy: 0.7500\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 12/100 [==>...........................] - ETA: 26:01 - loss: 0.5527 - accuracy: 0.7604\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 13/100 [==>...........................] - ETA: 25:37 - loss: 0.5366 - accuracy: 0.7740\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 14/100 [===>..........................] - ETA: 25:24 - loss: 0.5543 - accuracy: 0.7589\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 15/100 [===>..........................] - ETA: 25:06 - loss: 0.5499 - accuracy: 0.7625\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 16/100 [===>..........................] - ETA: 24:47 - loss: 0.5461 - accuracy: 0.7656\n",
      "Epoch 00008: accuracy did not improve from 0.90625\n",
      " 17/100 [====>.........................] - ETA: 24:26 - loss: 0.5602 - accuracy: 0.7537"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/chest_xray/train/pneumonia\\\\person1261_virus_2147.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f7eaad133d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                               callbacks=[checkpoint,early])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[1;34m(generator)\u001b[0m\n\u001b[0;32m    361\u001b[0m   \u001b[1;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(uid, i)\u001b[0m\n\u001b[0;32m    569\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m   \"\"\"\n\u001b[1;32m--> 571\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[0;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                            interpolation=self.interpolation)\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[1;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sibel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/chest_xray/train/pneumonia\\\\person1261_virus_2147.jpeg'"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(steps_per_epoch=100,\n",
    "                              generator=train_set, \n",
    "                              validation_data=test_set, \n",
    "                              validation_steps=10,\n",
    "                              epochs=100,\n",
    "                              callbacks=[checkpoint,early])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
